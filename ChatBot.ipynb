{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import create_qa_with_sources_chain, ConversationalRetrievalChain\n",
        "import gradio as gr\n",
        "\n",
        "loader = PyPDFLoader(\"/content/nz_infoo.pdf\")\n",
        "raw_documents = loader.load()\n",
        "\n",
        "# Split documents into chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=100, chunk_overlap=20, length_function=len\n",
        ")\n",
        "documents = text_splitter.split_documents(raw_documents)\n",
        "\n",
        "# Create FAISS vector store\n",
        "openai_api_key = \"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\"\n",
        "embeddings_model = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
        "db = FAISS.from_documents(documents, embeddings_model)\n",
        "retriever = db.as_retriever()\n",
        "\n",
        "# Initialize language model with the correct API key\n",
        "llm_src = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-16k\", openai_api_key=openai_api_key)\n",
        "\n",
        "# Create conversational retrieval chain\n",
        "retrieval_qa = ConversationalRetrievalChain.from_llm(\n",
        "    llm_src,\n",
        "    retriever,\n",
        "    return_source_documents=True,\n",
        ")\n",
        "\n",
        "def answer_question(question):\n",
        "    output = retrieval_qa({\n",
        "        \"question\": question,\n",
        "        \"chat_history\": []\n",
        "    })\n",
        "    return output['answer']\n",
        "\n",
        "iface = gr.Interface(fn=answer_question, inputs=\"text\", outputs=\"text\", title=\"DiscoverNZ\",\n",
        "                     theme=\"light\", description = 'Kia Ora! Ready to explore New Zealand?')\n",
        "\n",
        "iface.launch(inline=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 723
        },
        "id": "xlFL6NYMkJnw",
        "outputId": "e7c25840-5634-4149-cff7-0abb8be5d001"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gradio/blocks.py:530: UserWarning: Cannot load light. Caught Exception: 404 Client Error: Not Found for url: https://huggingface.co/api/spaces/light (Request ID: Root=1-65c90cad-7d446c726405121637d08f75;ae3a44c5-29db-428b-b6ce-8f306dd678e0)\n",
            "\n",
            "Sorry, we can't find the page you are looking for.\n",
            "  warnings.warn(f\"Cannot load {theme}. Caught Exception: {str(e)}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://cebc4bffe034bbf4bc.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://cebc4bffe034bbf4bc.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rrWONY7NYD9M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}